\begin{table}[t]
\centering
\caption{Success rates (\%) of LLMs across map-based tasks and SOSR tasks}
\label{tab:spatial_results}
\small
\begin{tabular}{l  cccc  c}
\toprule
\textbf{Task Type} & \textbf{Gemini-2.5 Flash} & \textbf{Gemini-2.0 Flash} & \textbf{GPT-5} & \textbf{GPT-4o} & \textbf{LLaMA-3-8b} \\
\midrule
\rowcolor{green!7}\multicolumn{6}{l}{\textbf{Map-based}} \\
Deterministic (Easy)      & 66.7 & 100 & 100 & 80  & 0 \\
Deterministic (Normal)    & 93.3 & 0   & 100 & 0   & 0 \\
Deterministic (Hard)      & 73.3 & 0   & 100 & 0   & 0 \\
Uncertain 1       & 90.0 & 0   & 100 & 0   & 0 \\
Uncertain 2       & 56.7 & 0   & 93.3 & 0  & 0 \\
\midrule
\rowcolor{blue!7}\multicolumn{6}{l}{\textbf{Safety-Oriented Spatial Reasoning (SOSR)}} \\
Direction (Easy)        & 98 & 99 & 98 & 94 & 7 \\
Direction (Normal)      & 100 & 72 & 82 & 66 & 12 \\
Direction (Hard)        & 100 & 42 & 100 & 53 & 51 \\
Emergency (Hard)       & 67 & 100 & 100 & 98 & 46 \\
Emergency (Easy)       & 100 & 100 & 100 & 100 & 100 \\
\bottomrule
\end{tabular}
\end{table}


\section{Main Results}
%%%%%%%%%%%%%%%%%%%%% Jung bin %%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Complete Information Task}
\label{sec:result_complete}

We evaluated five LLMs with \textbf{Gemini-2.5 Flash}, \textbf{Gemini-2.0 Flash}, \textbf{GPT-5}, \textbf{GPT-4o}, and \textbf{LLaMA-3-8b} through their public APIs rather than self-hosting, each tested 30 times per model. The experiments were designed to quantitatively and qualitatively assess each model’s spatial reasoning and decision-making ability under conditions of complete environmental certainty. 
Table~\ref{tab:spatial_results} and Fig.~\ref{fig:dotplot} summarize the overall success rates.

\paragraph{Evaluation setup.}
Each model was tested 30 times on three deterministic maps. 
The success rate was computed as
\[
\text{Success Rate (\%)} = \frac{N_\text{succ}}{30} \times 100.
\]

\begin{wrapfigure}[16]{r}{0.5\columnwidth}
  \vspace{-15pt}                        
  \centering
  \includegraphics[width=0.9\linewidth]{Figures/du_result6.pdf}
  \caption{Success rates of LLMs on deterministic and uncertain ASCII map tasks}
  \label{fig:dotplot}
  \vspace{-10pt}      
\end{wrapfigure}

where $N_\text{succ}$ denotes the number of successful runs. This metric represents the percentage of successful runs among 30 independent trials.
Performance was assessed under five strict criteria: 
(1) reaching \textbf{G} from \textbf{S}; 
(2) avoiding traversal or overstepping of \textbf{\#} (obstacle) cells; 
(3) preserving the input map structure, including dimensions, tokens, and spacing; 
(4) maintaining a continuous pathline between \textbf{S} and \textbf{G} under 4-neighborhood adjacency (up, down, left, right; no diagonals); and 
(5) ensuring that the visualized pathline matched the coordinate sequence in both order and alignment. 
\textbf{Path optimality was not considered;} the evaluation focused solely on the validity and consistency of generated routes.

\begin{wrapfigure}[17]{r}{0.45\columnwidth}
  \vspace{-17pt}
  \centering
  \includegraphics[width=0.93\linewidth]{Figures/llama_result3.pdf}
  \caption{Collapsed map structures generated by LLaMA-3-8b on (a) Deterministic Map (Easy) and (b) Uncertain Terrain Map 1}
  \label{fig:llama_result}
  \vspace{-10pt}
\end{wrapfigure}

\paragraph{Reliable and adaptive reasoning.} GPT-5 achieved a perfect 100\% success rate across all maps (Easy, Normal, and Hard), satisfying every evaluation criterion. 
It consistently preserved grid integrity, maintained spatial continuity, and demonstrated strong adherence to obstacle constraints. 
Notably, on the Normal map, GPT-5 produced multiple distinct yet valid route variants, indicating \textbf{flexible, problem-space-aware reasoning} rather than rigid pattern replication.

\paragraph{Non-gradual degradation.} Gemini-2.0 Flash and GPT-4o exhibited a catastrophic collapse once map complexity increased. 
Their success rates dropped sharply from 100\% and 80\% on the Easy map to 0\% on both the Normal and Hard maps (Table~\ref{tab:spatial_results}, Deterministic rows), revealing a \textbf{discrete collapse} rather than a gradual degradation.
In these cases, pathlines frequently terminated mid-route, suggesting an inability to sustain topological continuity or reason through obstacle-dense environments.

\paragraph{Structural breakdown.} LLaMA-3-8b failed completely with a 0\% success across all maps, generating disorganized grids filled with random symbols (., *, \#, ?), as illustrated in Fig.~\ref{fig:llama_result}. This outcome indicates a lack of comprehension of the ASCII-based spatial structure and an absence of coherent path-planning logic.

%%%%%%%%%%%%%%%%% Jaeyoon & Jung bin %%%%%%%%%%%%%%%%%%
\begin{table}[b]
    \vspace{-15pt}
    \centering
    \caption{Success rates(\%) of sequence-based reasoning tasks}
    \label{tab:map_success}
    \small
    \begin{tabular}{l cc}
        \toprule
        \textbf{} & 
        \textbf{Sequence Validation} & 
        \textbf{Sequence Masking} \\
        \midrule
        \cellcolor{orange!7}\textbf{API Models} & 
        \cellcolor{orange!7} & 
        \cellcolor{orange!7} \\
        \quad Gemini-2.5 Flash & 
            51\% & 68\%\\
        \quad Gemini-2.0 Flash & 
            53\% & 12\%\\
        \quad GPT-5 & 
            64\% & 92\% \\
        \quad GPT-4o & 
            50\% & 54\% \\
        \midrule
        \cellcolor{yellow!7}\textbf{Open-source Models} & 
        \cellcolor{yellow!7} & 
        \cellcolor{yellow!7} \\
        \quad LLaVA-v1.6-vicuna-13b & 
            37\% & 24\% \\
        \quad LLaVA-v1.6-vicuna-7b & 
            39\% & 23\%\\
        \quad LLaVA-v1.6-mistral-7b  & 
            39\% & 59\% \\
        \quad LLaVA-v1.5-7b  & 
            48\% & 10\% \\
        \quad Qwen2.5-VL-7B-Instruct  & 
            52\% & 52\% \\
        \quad Qwen2.5-VL-3B-Instruct  & 
            44\% & 54\% \\
        \quad Qwen2.5-Omni-7B  & 
            52\% & 58\% \\
        \quad InternVL3-14B  & 
            49\% & 67\% \\
        \bottomrule
    \end{tabular}
\end{table}


\subsection{Incomplete Information Task}
\subsubsection{Sequence-Based Reasoning Task} 
\paragraph{Evaluation setup.}
This task requires visual inputs, and thus VLMs must be employed. We selected several representative VLMs that are frequently compared in recent studies, including LLaVA, Qwen, and InternVL. The chosen models span a wide range of parameter scales from 3B to 14B models to ensure coverage across diverse capacity levels.
We constructed a dataset of 100 short navigation trajectories evenly divided between indoor and outdoor environments, each containing both left and right turn movements. 
From each video, we extracted five representative frames. In the sequence validation task, the five frames were concatenated in their natural temporal order. 
To address cases where the model could not process multiple images simultaneously, we combined the sequence frames into a single concatenated image.
For the sequence masking task, the 2nd, 3rd, and 5th frames were combined while the 4th frame was masked out, and the 1st and 4th frames were used as candidate options for selection. 

The prompts used in these tasks are shown in Fig.~\ref{fig_overall}. For sequence masking task, the correct answer was always assigned to option (b), and model accuracy was computed based on the proportion of times the model selected (b).
For the sequence validation task, ground-truth annotations for these cases were manually labeled to ensure consistency, and correctness was again computed by comparing model judgments with human labels.
We further conducted a qualitative evaluation through manual inspection of reasoning traces. 

\paragraph{Validation results.}
When comparing accuracies, GPT-5 achieved the highest score, while LLaVA-v1.6-vicuna-13b was the lowest. 
An interesting observation was that the models exhibited a strong bias toward answering ``right.'' Regardless of the actual turning direction, they frequently responded with ``right,'' which resulted in accuracy rates mostly around 40–60\%. %To verify this tendency, we explicitly asked the question ``Did I turn left?'' — yet the models still produced left/right answers at approximately the same probability.
Though merely a casual speculation, the observed bias may be attributed to sycophantic behavior, whereby models tend to produce agreeable or seemingly positive responses. Given that ``right'' often conveys affirmative meaning, the models might consequently favor it over more neutral options~\cite{sharma2023towards,malmqvist2025sycophancy}.

\paragraph{Masking results.}
When comparing accuracies, GPT-5 achieved the highest score, while LLaVA-v1.5-7b showed the lowest. 
In most cases, the model’s accuracy was close to random, suggesting that it often failed to grasp the given context and instead fabricated information, which is a clear sign of hallucination~\cite{huang2025survey,bai2024hallucination}. Although the model occasionally produced correct and contextually consistent answers, its overall reliability remained questionable.

Examining the hallucinated cases revealed several distinct patterns: in some instances, the model incorrectly judged continuity, claiming that (b) depicted a later moment in the sequence or that (a) appeared more consistent; in others, it refused to answer altogether. There were also explicit hallucinations, such as inventing nonexistent columns (e.g., ``C'' or ``D'') or referring to irrelevant images like (J) as the correct answer. Notably, LLaVA-v1.5-7b showed particularly unstable behavior, producing irrelevant outputs other than a or b in nearly 30\% of trials, indicating a severe lack of reliability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Map-Based Uncertain Terrain Tasks}
\paragraph{Evaluation setup.} Each model was evaluated 30 times on two uncertain-terrain maps (Uncertain Ver.~1 and Ver.~2), following the same experimental framework described in Section~\ref{sec:result_complete}. In addition to the five deterministic evaluation criteria, models were required to handle unknown ``?'' cells according to their self-chosen assumption (either \textit{passable} or \textit{not passable}). This additional condition enabled the assessment of how models reason and plan under partial observability and incomplete environmental information, with quantitative results shown in Table~\ref{tab:spatial_results}.

\paragraph{Constraint-aware reasoning and safe adaptation.}
GPT-5 again achieved the highest performance, with 100\% success on Uncertain Ver.~1 and 93\% on Ver.~2. In all Ver.~1 trials, it explicitly stated, ``I assume that unknown terrain (?) is not passable,'' demonstrating a stable safety-first bias. When the goal in Ver.~2 became unreachable under this assumption, GPT-5 correctly responded ``\textit{No path exists under this assumption}'' in 26.7\% of the runs. Although two Ver.~2 failures (6.7\%) involved diagonal movement, an explicitly prohibited action, such violations emphasize a critical insight: \textbf{high accuracy does not imply safety}. Even rare breaches of explicit constraints can pose \textbf{serious risks in embodied robotic systems}.

\paragraph{Partial alignment, fragile consistency.} 
Gemini-2.5 Flash showed partial alignment with GPT-5’s reasoning but lower reliability.
While it adopted the same ``not passable'' assumption in most Ver.~1 runs (97\%), its success rate dropped to 57\% on Ver.~2, with frequent failures such as obstacle traversal and map collapse.
These results indicate that although the model could imitate safety-oriented reasoning, it failed to maintain constraint consistency once uncertainty was introduced.
Similarly, LLaMA-3-8b showed the same collapse pattern observed in the complete-task results, failing entirely on uncertain terrain maps (Fig.~\ref{fig:llama_result}).

\begin{figure}[b]
    \centering
    \includegraphics[width=0.95\linewidth]{Figures/bob_figure3.pdf}
    \caption{Representative failure types in the \textit{Back of the Building} task. 
(a) \textbf{Structural collapse:} Loss of global topology, producing incoherent or missing spatial structures.
(b) \textbf{Directional error:} The agent failed to reach the rear of the building.
(c) \textbf{Constraint violation:} The path intersected obstacles, yielding unsafe or infeasible planning.
(d) \textbf{Waypoint error:} The model failed to place waypoints at directional transition points.}
    \label{fig_bob}
\end{figure}

\subsubsection{Back of the Building Task}
In this task, we tested three LLMs, namely \textbf{ChatGPT-4o}, \textbf{Claude Opus 4.1}, and \textbf{Claude Sonnet 4}, each prompted with an identical instruction ``Navigate the robot to the back of the building.''
The task required inferring the robot’s position within the scene, mentally transforming a first-person viewpoint into a top-down layout, and generating a coherent map that links visual perception with spatial reasoning.

\paragraph{Results.}
The tested models exhibited \textbf{limited capability in establishing stable spatial correspondences} between the visual scene and the generated map.
Most models produced partially plausible layouts but failed to consistently identify the correct orientation, preserve the structural integrity of the building, or maintain feasible trajectories.
As shown in Fig.~\ref{fig_bob}, these results indicate recurring breakdowns in visual–spatial grounding and constraint adherence, revealing instability in high-level spatial reasoning across models.
Detailed prompts, visual outputs, and representative examples for the Back of the Building task are included in the Appendix for reference.

%%%%%%%%%%%%%%% Jua %%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t!] % b: Bottom, !: LaTeX에게 강력히 권고, *: 페이지 전체 너비
    \centering % 전체 figure 환경을 중앙 정렬

    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/SOSR_radar.pdf}
        \caption{A radar chart comparing model performance on a series of SOSR task.} 
        \label{fig_SOSR_Rader}
    \end{subfigure}
    \hfill % 두 subfigure 사이의 공간을 최대로 벌려줌
    % 오른쪽 그림 (Figure 6)
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/Response.pdf}
        \caption{Response frequencies of Gemini-2.5 Flash for the emergency escape task (hard difficulty).}
        \label{fig_SOSR_ob3}
    \end{subfigure}
    
    % 만약 두 그림을 아우르는 전체 캡션이 필요하다면 아래 주석을 해제하세요.
    % \caption{Overall performance and response analysis on SOSR tasks.}
    % \label{fig_overall_analysis}
    \caption{Overall performance and response analysis on SOSR task.}
\end{figure*}

\begin{figure}[b]
  \vspace{-10pt}                           
  \centering
  \includegraphics[width=\linewidth]{Figures/entropy.pdf}
  % \includesvg[width=0.5\linewidth]{Figures/radar_chart_art.pdf}
  \caption{Entropy values computed from model-generated responses for SOSR task.}
  \label{entropy}
  % \vspace{-10pt}      
\end{figure}


\subsection{Safety-Oriented Spatial
Reasoning (SOSR) Task}

\paragraph{Evaluation setup.} The models evaluated in our task are listed in Table~\ref{tab:spatial_results}. The prompt used for the evaluation is presented in Fig.~\ref{fig_overall}. To assess the consistency of the models' responses to the same problem, we ran the experiment 100 times for each model using the identical prompt. All API parameters were set to their default values. Fig.~\ref{fig_SOSR_Rader} summarizes the overall performance on the SOSR task. 

\paragraph{Critical failure rate.} In the emergency escape experiment, the models exhibited alarming behaviors when confronted with safety-critical prompts. As shown in Fig.~\ref{fig_SOSR_ob3}, Gemini-2.5 Flash directed users toward the professor’s office where the prompt mentioned important personal materials in 32\% of trials, prioritizing document retrieval over evacuation. This behavior represents a direct threat to human safety. Additionally, in 1\% of the trials, the model instructed users to head to the server room, a location never mentioned in the prompt. This hallucinated reasoning, implying that important items might be in the server room, further amplifies the danger, as the server room is itself a high-risk area with potential explosion hazards. The irregularity of these decisions is further highlighted by the entropy analysis in Fig.~\ref{entropy}. GPT-4o, in contrast, refused to respond due to its policy on life-and-safety-related prompts, whereas Gemini-2.5 Flash produced confident yet hazardous responses.

\paragraph{Safety-critical.} The latest LLMs \textbf{do not always guarantee superior performance} over their predecessors. This was evident in the ‘hard’ level of the emergency escape experiment, where Gemini-2.5 Flash's performance was 40\% lower than that of Gemini-2.0 Flash. This finding is particularly notable: whereas Gemini-2.0 Flash demonstrated a perfect (100\%) understanding of the context and the importance of human safety, Gemini-2.5 Flash failed to comprehend the identical prompt and made a choice that was hazardous to human safety.

\paragraph{Prompt length.} A longer prompt length does not invariably lead to performance degradation. While performance generally decreased with rising task difficulty, some exceptions were observed. For instance, in the direction task, Gemini-2.5 Flash performed 2\% worse on the ‘easy’ level than on the ‘normal’ level. Similarly, GPT-5’s performance on the same test was 18\% lower on the ‘normal’ level compared to the ‘hard’ level. Although each subsequent difficulty level added one or two sentences to the prompt, these results indicate that increased prompt length does not necessarily cause a decline in model performance.

\subsection{Limitations}
% 서버 스펙 명시
All experiments were conducted on a single NVIDIA RTX 6000 Ada Generation GPU. Consequently, our evaluation was confined to models that could be accommodated by this hardware, excluding those with substantial computational requirements and parameter counts.
For the priliminary evaluation, we used 100 sequences. Although the dataset size was limited, we empirically judged that 100 samples were sufficient to approximate a normal distribution given the binary nature of the task. Due to constraints in manpower and time, we limited our study to this scale. While this setup allows us to capture the general behavioral tendencies of the models, it is not sufficient for rigorous statistical analysis. Future studies could build upon larger benchmark datasets, such as VLN-CE, to enable more extensive evaluations.