\section{Self-Refining Prompt Evaluation Process}

In some cases, prompts are written with assistance from a language model. However, even in such cases, problems may still occur when using the generated prompt, requiring further refinement. To automate this feedback loop, we designed a process in which the language model repeatedly evaluates and revises its own prompt until no potential issues remain.

More specifically, we first describe my Back of the Building navigation task to the model and ask it to write a prompt. The model then evaluates that prompt, listing possible failure scenarios, and modifies the prompt to prevent such issues. This cycle continues until the model judges that no further problems exist. All experiments were conducted using GPT-4o and Claude Sonnet 4.

After several iterations, it was observed that the models tended to become overly cautious. For instance, they often over-considered unrealistic factors, situations irrelevant to the described task, or even contradictions to the given setup, sometimes modifying the prompt so drastically that they refused to answer altogether. In certain cases, they generated overly elaborate concerns such as considering whether the photo might depict a location in North Korea while the current position is in South Korea, whether the site could be religiously restricted and thus inaccessible to robots, whether a map API request should be made before proceeding, or whether connecting competing stores in a straight line might raise ethical issues.

During this iterative refinement, the model frequently deviated from the original intent, making assumptions about unspecified experimental conditions. For example, it introduced the use of unavailable sensors such as LiDAR, considered real-world robot control settings, altered input/output formats, and even redefined the task itself. These cases demonstrate that when faced with ambiguity, the language model tends to form incorrect assumptions and become strongly biased toward them, leading to severe reasoning errors.